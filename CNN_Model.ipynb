{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "input_path = \"C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=os.listdir(input_path)\n",
    "labels=[i for i in range(len(categories))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict=dict(zip(categories,labels)) #empty dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'car': 0, 'cat': 1}\n",
      "['car', 'cat']\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)\n",
    "print(categories)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/car\\car1.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/car\\car2.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/car\\car3.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/car\\car4.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/car\\car5.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/car\\carr.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/cat\\cat.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/cat\\cat1.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/cat\\cat2.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/cat\\cat3.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/cat\\cat4.jpg\n",
      "C:/Users/DK/Desktop/upgrad/handon/cnn/image/input/cat\\cat5.jpg\n"
     ]
    }
   ],
   "source": [
    "img_size=100\n",
    "data=[]\n",
    "target=[]\n",
    "\n",
    "for category in categories:\n",
    "    folder_path=os.path.join(input_path,category)\n",
    "    img_names=os.listdir(folder_path)\n",
    "        \n",
    "    for img_name in img_names:\n",
    "        img_path=os.path.join(folder_path,img_name)\n",
    "        img=cv2.imread(img_path)\n",
    "        print(img_path)\n",
    "        \n",
    "        try:  \n",
    "            resized=cv2.resize(img,(img_size,img_size))\n",
    "            #resizing the image  into 100x100, since we need a fixed common size for all the images in the dataset\n",
    "            data.append(resized)\n",
    "            target.append(label_dict[category])\n",
    "            #appending the image and the label(categorized) into the list (dataset)\n",
    "        except Exception as e:\n",
    "            print('Exception:',e)\n",
    "            #if any exception rasied, the exception will be printed here. And pass to the next image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 36,  94,  83],\n",
      "        [ 48, 108,  97],\n",
      "        [ 52, 118, 112],\n",
      "        ...,\n",
      "        [ 20,  40,  29],\n",
      "        [ 25,  39,  23],\n",
      "        [148, 119,  50]],\n",
      "\n",
      "       [[ 37,  70,  52],\n",
      "        [ 38,  81,  65],\n",
      "        [ 37,  77,  65],\n",
      "        ...,\n",
      "        [ 21,  27,  15],\n",
      "        [ 23,  37,  25],\n",
      "        [153, 124,  55]],\n",
      "\n",
      "       [[ 28,  37,  17],\n",
      "        [ 27,  46,  27],\n",
      "        [ 38,  66,  46],\n",
      "        ...,\n",
      "        [ 70,  77,  47],\n",
      "        [ 44,  35,  17],\n",
      "        [151, 123,  58]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[137, 147, 148],\n",
      "        [138, 148, 148],\n",
      "        [132, 141, 144],\n",
      "        ...,\n",
      "        [138, 149, 163],\n",
      "        [141, 152, 166],\n",
      "        [141, 150, 164]],\n",
      "\n",
      "       [[135, 144, 147],\n",
      "        [131, 140, 143],\n",
      "        [137, 146, 150],\n",
      "        ...,\n",
      "        [137, 149, 161],\n",
      "        [140, 153, 167],\n",
      "        [140, 152, 164]],\n",
      "\n",
      "       [[133, 143, 143],\n",
      "        [137, 149, 154],\n",
      "        [139, 148, 151],\n",
      "        ...,\n",
      "        [136, 147, 161],\n",
      "        [137, 149, 161],\n",
      "        [139, 149, 158]]], dtype=uint8), array([[[134, 159, 190],\n",
      "        [137, 162, 194],\n",
      "        [137, 165, 195],\n",
      "        ...,\n",
      "        [172, 206, 222],\n",
      "        [176, 202, 214],\n",
      "        [173, 199, 211]],\n",
      "\n",
      "       [[131, 156, 188],\n",
      "        [135, 160, 193],\n",
      "        [137, 165, 195],\n",
      "        ...,\n",
      "        [181, 213, 230],\n",
      "        [182, 208, 220],\n",
      "        [179, 205, 217]],\n",
      "\n",
      "       [[133, 158, 190],\n",
      "        [134, 159, 191],\n",
      "        [137, 165, 195],\n",
      "        ...,\n",
      "        [188, 217, 234],\n",
      "        [184, 210, 222],\n",
      "        [180, 206, 218]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[109, 105, 100],\n",
      "        [113, 110, 105],\n",
      "        [109, 104, 100],\n",
      "        ...,\n",
      "        [112, 114, 118],\n",
      "        [103, 108, 111],\n",
      "        [108, 110, 114]],\n",
      "\n",
      "       [[109, 105, 100],\n",
      "        [109, 105, 100],\n",
      "        [106, 103,  98],\n",
      "        ...,\n",
      "        [113, 118, 121],\n",
      "        [109, 115, 117],\n",
      "        [101, 106, 109]],\n",
      "\n",
      "       [[110, 106, 101],\n",
      "        [106, 102,  97],\n",
      "        [111, 106, 102],\n",
      "        ...,\n",
      "        [106, 111, 114],\n",
      "        [109, 114, 117],\n",
      "        [109, 114, 117]]], dtype=uint8), array([[[146,  83,   9],\n",
      "        [146,  83,   9],\n",
      "        [146,  84,  13],\n",
      "        ...,\n",
      "        [150, 100,  40],\n",
      "        [151, 101,  41],\n",
      "        [151, 104,  36]],\n",
      "\n",
      "       [[147,  83,  12],\n",
      "        [148,  84,  13],\n",
      "        [146,  84,  13],\n",
      "        ...,\n",
      "        [150, 103,  41],\n",
      "        [150, 104,  40],\n",
      "        [151, 104,  42]],\n",
      "\n",
      "       [[147,  82,  13],\n",
      "        [146,  82,  11],\n",
      "        [146,  84,  13],\n",
      "        ...,\n",
      "        [150, 106,  42],\n",
      "        [150, 107,  40],\n",
      "        [149, 104,  43]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 69,  64,  55],\n",
      "        [242, 238, 237],\n",
      "        [232, 231, 226],\n",
      "        ...,\n",
      "        [117, 110,  91],\n",
      "        [109,  99,  82],\n",
      "        [105, 101,  85]],\n",
      "\n",
      "       [[ 93,  87,  76],\n",
      "        [ 97,  95,  90],\n",
      "        [100,  95,  92],\n",
      "        ...,\n",
      "        [119, 112,  93],\n",
      "        [115, 107,  90],\n",
      "        [122, 115,  98]],\n",
      "\n",
      "       [[110, 103,  90],\n",
      "        [ 94, 100,  86],\n",
      "        [115, 106,  93],\n",
      "        ...,\n",
      "        [115, 108,  89],\n",
      "        [123, 120,  99],\n",
      "        [121, 114,  94]]], dtype=uint8), array([[[ 29,  53,  29],\n",
      "        [  1,  11,   1],\n",
      "        [  9,  21,  11],\n",
      "        ...,\n",
      "        [ 89, 151, 127],\n",
      "        [ 77, 129, 106],\n",
      "        [ 89, 129, 112]],\n",
      "\n",
      "       [[ 16,  37,  14],\n",
      "        [  6,  22,   4],\n",
      "        [  1,   2,   0],\n",
      "        ...,\n",
      "        [ 31, 118,  92],\n",
      "        [ 21, 103,  80],\n",
      "        [ 39, 118, 104]],\n",
      "\n",
      "       [[  3,   4,   0],\n",
      "        [  2,   6,   0],\n",
      "        [  2,   3,   1],\n",
      "        ...,\n",
      "        [ 31, 116,  94],\n",
      "        [ 65, 150, 122],\n",
      "        [ 97, 165, 145]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 30, 106,  98],\n",
      "        [ 39, 116, 113],\n",
      "        [ 55, 148, 144],\n",
      "        ...,\n",
      "        [123, 132, 135],\n",
      "        [152, 156, 157],\n",
      "        [131, 138, 140]],\n",
      "\n",
      "       [[ 30, 107, 104],\n",
      "        [ 51, 116, 116],\n",
      "        [ 31, 113, 114],\n",
      "        ...,\n",
      "        [135, 143, 143],\n",
      "        [131, 136, 137],\n",
      "        [126, 135, 138]],\n",
      "\n",
      "       [[ 21, 101,  96],\n",
      "        [ 27, 104, 100],\n",
      "        [ 47, 119, 117],\n",
      "        ...,\n",
      "        [125, 142, 139],\n",
      "        [145, 150, 149],\n",
      "        [133, 141, 141]]], dtype=uint8), array([[[211, 212, 216],\n",
      "        [202, 199, 201],\n",
      "        [204, 203, 205],\n",
      "        ...,\n",
      "        [186, 166, 155],\n",
      "        [180, 158, 146],\n",
      "        [178, 158, 147]],\n",
      "\n",
      "       [[223, 227, 233],\n",
      "        [221, 224, 232],\n",
      "        [213, 212, 216],\n",
      "        ...,\n",
      "        [183, 159, 146],\n",
      "        [171, 147, 135],\n",
      "        [176, 154, 143]],\n",
      "\n",
      "       [[221, 227, 233],\n",
      "        [238, 247, 250],\n",
      "        [203, 210, 212],\n",
      "        ...,\n",
      "        [181, 160, 153],\n",
      "        [180, 158, 147],\n",
      "        [179, 153, 136]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[145, 155, 168],\n",
      "        [ 95,  97,  96],\n",
      "        [110, 115, 119],\n",
      "        ...,\n",
      "        [138, 128, 118],\n",
      "        [ 74,  62,  44],\n",
      "        [103,  92,  78]],\n",
      "\n",
      "       [[184, 204, 217],\n",
      "        [130, 132, 142],\n",
      "        [ 91,  89,  81],\n",
      "        ...,\n",
      "        [ 81,  67,  55],\n",
      "        [ 74,  61,  46],\n",
      "        [112,  99,  87]],\n",
      "\n",
      "       [[ 97,  99, 100],\n",
      "        [115, 120, 124],\n",
      "        [117, 121, 128],\n",
      "        ...,\n",
      "        [ 64,  51,  37],\n",
      "        [ 80,  67,  51],\n",
      "        [ 85,  72,  58]]], dtype=uint8), array([[[ 72, 122, 129],\n",
      "        [ 72, 122, 130],\n",
      "        [ 74, 124, 133],\n",
      "        ...,\n",
      "        [ 67, 128, 121],\n",
      "        [ 73, 131, 129],\n",
      "        [ 75, 133, 132]],\n",
      "\n",
      "       [[ 66, 121, 124],\n",
      "        [ 67, 124, 126],\n",
      "        [ 69, 126, 128],\n",
      "        ...,\n",
      "        [ 52, 116, 110],\n",
      "        [ 67, 128, 127],\n",
      "        [ 73, 130, 129]],\n",
      "\n",
      "       [[ 62, 115, 118],\n",
      "        [ 62, 118, 118],\n",
      "        [ 70, 127, 129],\n",
      "        ...,\n",
      "        [ 71, 130, 125],\n",
      "        [ 66, 125, 125],\n",
      "        [ 67, 122, 125]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 75, 144, 133],\n",
      "        [ 77, 148, 136],\n",
      "        [ 81, 149, 142],\n",
      "        ...,\n",
      "        [ 73, 142, 130],\n",
      "        [ 86, 151, 139],\n",
      "        [ 77, 138, 128]],\n",
      "\n",
      "       [[ 63, 138, 122],\n",
      "        [ 65, 144, 123],\n",
      "        [ 69, 147, 133],\n",
      "        ...,\n",
      "        [ 68, 134, 123],\n",
      "        [ 77, 139, 131],\n",
      "        [ 71, 134, 124]],\n",
      "\n",
      "       [[ 50, 128, 109],\n",
      "        [ 75, 153, 136],\n",
      "        [ 59, 141, 120],\n",
      "        ...,\n",
      "        [ 59, 119, 111],\n",
      "        [ 77, 137, 129],\n",
      "        [ 91, 150, 142]]], dtype=uint8), array([[[247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        ...,\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247]],\n",
      "\n",
      "       [[247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        ...,\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247]],\n",
      "\n",
      "       [[247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        ...,\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        ...,\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247]],\n",
      "\n",
      "       [[247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        ...,\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247]],\n",
      "\n",
      "       [[247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        ...,\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247],\n",
      "        [247, 247, 247]]], dtype=uint8), array([[[255, 253, 252],\n",
      "        [255, 253, 252],\n",
      "        [255, 253, 252],\n",
      "        ...,\n",
      "        [255, 254, 253],\n",
      "        [255, 254, 253],\n",
      "        [255, 254, 253]],\n",
      "\n",
      "       [[255, 253, 253],\n",
      "        [255, 253, 252],\n",
      "        [255, 253, 252],\n",
      "        ...,\n",
      "        [255, 254, 253],\n",
      "        [255, 254, 253],\n",
      "        [255, 254, 253]],\n",
      "\n",
      "       [[255, 253, 252],\n",
      "        [255, 253, 252],\n",
      "        [255, 253, 252],\n",
      "        ...,\n",
      "        [255, 254, 253],\n",
      "        [255, 254, 253],\n",
      "        [255, 254, 253]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]],\n",
      "\n",
      "       [[  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        ...,\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1],\n",
      "        [  1,   1,   1]]], dtype=uint8), array([[[ 16,  12,   7],\n",
      "        [ 14,  10,   5],\n",
      "        [ 13,   9,   4],\n",
      "        ...,\n",
      "        [119, 113, 106],\n",
      "        [120, 114, 107],\n",
      "        [120, 114, 107]],\n",
      "\n",
      "       [[ 15,  12,   7],\n",
      "        [ 14,  10,   5],\n",
      "        [ 13,   8,   5],\n",
      "        ...,\n",
      "        [122, 116, 109],\n",
      "        [121, 115, 108],\n",
      "        [122, 116, 109]],\n",
      "\n",
      "       [[ 16,  13,   8],\n",
      "        [ 15,  11,   6],\n",
      "        [ 14,  10,   5],\n",
      "        ...,\n",
      "        [124, 118, 111],\n",
      "        [123, 117, 110],\n",
      "        [124, 118, 111]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[130, 131, 127],\n",
      "        [146, 147, 145],\n",
      "        [137, 136, 132],\n",
      "        ...,\n",
      "        [136, 141, 140],\n",
      "        [137, 139, 139],\n",
      "        [152, 154, 154]],\n",
      "\n",
      "       [[134, 135, 133],\n",
      "        [133, 134, 132],\n",
      "        [128, 129, 127],\n",
      "        ...,\n",
      "        [129, 135, 134],\n",
      "        [140, 145, 143],\n",
      "        [118, 121, 119]],\n",
      "\n",
      "       [[113, 114, 112],\n",
      "        [141, 144, 142],\n",
      "        [137, 142, 140],\n",
      "        ...,\n",
      "        [142, 145, 143],\n",
      "        [134, 137, 135],\n",
      "        [120, 125, 123]]], dtype=uint8), array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8), array([[[51, 46, 45],\n",
      "        [51, 46, 45],\n",
      "        [51, 46, 45],\n",
      "        ...,\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3]],\n",
      "\n",
      "       [[52, 47, 46],\n",
      "        [51, 46, 45],\n",
      "        [51, 46, 45],\n",
      "        ...,\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3]],\n",
      "\n",
      "       [[52, 47, 46],\n",
      "        [54, 47, 44],\n",
      "        [52, 47, 47],\n",
      "        ...,\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[28, 26, 26],\n",
      "        [27, 24, 26],\n",
      "        [27, 25, 26],\n",
      "        ...,\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3]],\n",
      "\n",
      "       [[28, 26, 26],\n",
      "        [26, 24, 24],\n",
      "        [26, 25, 25],\n",
      "        ...,\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3]],\n",
      "\n",
      "       [[28, 26, 26],\n",
      "        [27, 25, 25],\n",
      "        [27, 24, 25],\n",
      "        ...,\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3],\n",
      "        [ 2,  1,  3]]], dtype=uint8), array([[[ 79, 107, 118],\n",
      "        [ 85, 111, 123],\n",
      "        [ 91, 115, 127],\n",
      "        ...,\n",
      "        [111, 116, 117],\n",
      "        [ 96, 100, 101],\n",
      "        [ 90,  91,  89]],\n",
      "\n",
      "       [[ 81, 109, 120],\n",
      "        [ 86, 112, 124],\n",
      "        [ 92, 117, 128],\n",
      "        ...,\n",
      "        [112, 117, 119],\n",
      "        [ 97, 101, 102],\n",
      "        [ 91,  92,  90]],\n",
      "\n",
      "       [[ 83, 111, 122],\n",
      "        [ 88, 114, 126],\n",
      "        [ 94, 118, 130],\n",
      "        ...,\n",
      "        [114, 118, 120],\n",
      "        [ 99, 104, 104],\n",
      "        [ 92,  93,  91]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[141, 148, 155],\n",
      "        [138, 146, 153],\n",
      "        [134, 142, 149],\n",
      "        ...,\n",
      "        [ 26,  26,  32],\n",
      "        [ 13,  13,  19],\n",
      "        [ 14,  14,  19]],\n",
      "\n",
      "       [[136, 144, 151],\n",
      "        [127, 135, 142],\n",
      "        [118, 126, 133],\n",
      "        ...,\n",
      "        [ 26,  26,  32],\n",
      "        [ 31,  31,  37],\n",
      "        [ 18,  18,  24]],\n",
      "\n",
      "       [[124, 132, 139],\n",
      "        [118, 126, 133],\n",
      "        [109, 118, 124],\n",
      "        ...,\n",
      "        [ 17,  17,  23],\n",
      "        [ 11,  11,  17],\n",
      "        [ 17,  17,  23]]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data=np.array(data)/255.0\n",
    "data=np.reshape(data,(data.shape[0],img_size,img_size,3))\n",
    "target=np.array(target)\n",
    "from keras.utils import np_utils\n",
    "new_target=np_utils.to_categorical(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.14117647 0.36862745 0.3254902 ]\n",
      "   [0.18823529 0.42352941 0.38039216]\n",
      "   [0.20392157 0.4627451  0.43921569]\n",
      "   ...\n",
      "   [0.07843137 0.15686275 0.11372549]\n",
      "   [0.09803922 0.15294118 0.09019608]\n",
      "   [0.58039216 0.46666667 0.19607843]]\n",
      "\n",
      "  [[0.14509804 0.2745098  0.20392157]\n",
      "   [0.14901961 0.31764706 0.25490196]\n",
      "   [0.14509804 0.30196078 0.25490196]\n",
      "   ...\n",
      "   [0.08235294 0.10588235 0.05882353]\n",
      "   [0.09019608 0.14509804 0.09803922]\n",
      "   [0.6        0.48627451 0.21568627]]\n",
      "\n",
      "  [[0.10980392 0.14509804 0.06666667]\n",
      "   [0.10588235 0.18039216 0.10588235]\n",
      "   [0.14901961 0.25882353 0.18039216]\n",
      "   ...\n",
      "   [0.2745098  0.30196078 0.18431373]\n",
      "   [0.17254902 0.1372549  0.06666667]\n",
      "   [0.59215686 0.48235294 0.22745098]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5372549  0.57647059 0.58039216]\n",
      "   [0.54117647 0.58039216 0.58039216]\n",
      "   [0.51764706 0.55294118 0.56470588]\n",
      "   ...\n",
      "   [0.54117647 0.58431373 0.63921569]\n",
      "   [0.55294118 0.59607843 0.65098039]\n",
      "   [0.55294118 0.58823529 0.64313725]]\n",
      "\n",
      "  [[0.52941176 0.56470588 0.57647059]\n",
      "   [0.51372549 0.54901961 0.56078431]\n",
      "   [0.5372549  0.57254902 0.58823529]\n",
      "   ...\n",
      "   [0.5372549  0.58431373 0.63137255]\n",
      "   [0.54901961 0.6        0.65490196]\n",
      "   [0.54901961 0.59607843 0.64313725]]\n",
      "\n",
      "  [[0.52156863 0.56078431 0.56078431]\n",
      "   [0.5372549  0.58431373 0.60392157]\n",
      "   [0.54509804 0.58039216 0.59215686]\n",
      "   ...\n",
      "   [0.53333333 0.57647059 0.63137255]\n",
      "   [0.5372549  0.58431373 0.63137255]\n",
      "   [0.54509804 0.58431373 0.61960784]]]\n",
      "\n",
      "\n",
      " [[[0.5254902  0.62352941 0.74509804]\n",
      "   [0.5372549  0.63529412 0.76078431]\n",
      "   [0.5372549  0.64705882 0.76470588]\n",
      "   ...\n",
      "   [0.6745098  0.80784314 0.87058824]\n",
      "   [0.69019608 0.79215686 0.83921569]\n",
      "   [0.67843137 0.78039216 0.82745098]]\n",
      "\n",
      "  [[0.51372549 0.61176471 0.7372549 ]\n",
      "   [0.52941176 0.62745098 0.75686275]\n",
      "   [0.5372549  0.64705882 0.76470588]\n",
      "   ...\n",
      "   [0.70980392 0.83529412 0.90196078]\n",
      "   [0.71372549 0.81568627 0.8627451 ]\n",
      "   [0.70196078 0.80392157 0.85098039]]\n",
      "\n",
      "  [[0.52156863 0.61960784 0.74509804]\n",
      "   [0.5254902  0.62352941 0.74901961]\n",
      "   [0.5372549  0.64705882 0.76470588]\n",
      "   ...\n",
      "   [0.7372549  0.85098039 0.91764706]\n",
      "   [0.72156863 0.82352941 0.87058824]\n",
      "   [0.70588235 0.80784314 0.85490196]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.42745098 0.41176471 0.39215686]\n",
      "   [0.44313725 0.43137255 0.41176471]\n",
      "   [0.42745098 0.40784314 0.39215686]\n",
      "   ...\n",
      "   [0.43921569 0.44705882 0.4627451 ]\n",
      "   [0.40392157 0.42352941 0.43529412]\n",
      "   [0.42352941 0.43137255 0.44705882]]\n",
      "\n",
      "  [[0.42745098 0.41176471 0.39215686]\n",
      "   [0.42745098 0.41176471 0.39215686]\n",
      "   [0.41568627 0.40392157 0.38431373]\n",
      "   ...\n",
      "   [0.44313725 0.4627451  0.4745098 ]\n",
      "   [0.42745098 0.45098039 0.45882353]\n",
      "   [0.39607843 0.41568627 0.42745098]]\n",
      "\n",
      "  [[0.43137255 0.41568627 0.39607843]\n",
      "   [0.41568627 0.4        0.38039216]\n",
      "   [0.43529412 0.41568627 0.4       ]\n",
      "   ...\n",
      "   [0.41568627 0.43529412 0.44705882]\n",
      "   [0.42745098 0.44705882 0.45882353]\n",
      "   [0.42745098 0.44705882 0.45882353]]]\n",
      "\n",
      "\n",
      " [[[0.57254902 0.3254902  0.03529412]\n",
      "   [0.57254902 0.3254902  0.03529412]\n",
      "   [0.57254902 0.32941176 0.05098039]\n",
      "   ...\n",
      "   [0.58823529 0.39215686 0.15686275]\n",
      "   [0.59215686 0.39607843 0.16078431]\n",
      "   [0.59215686 0.40784314 0.14117647]]\n",
      "\n",
      "  [[0.57647059 0.3254902  0.04705882]\n",
      "   [0.58039216 0.32941176 0.05098039]\n",
      "   [0.57254902 0.32941176 0.05098039]\n",
      "   ...\n",
      "   [0.58823529 0.40392157 0.16078431]\n",
      "   [0.58823529 0.40784314 0.15686275]\n",
      "   [0.59215686 0.40784314 0.16470588]]\n",
      "\n",
      "  [[0.57647059 0.32156863 0.05098039]\n",
      "   [0.57254902 0.32156863 0.04313725]\n",
      "   [0.57254902 0.32941176 0.05098039]\n",
      "   ...\n",
      "   [0.58823529 0.41568627 0.16470588]\n",
      "   [0.58823529 0.41960784 0.15686275]\n",
      "   [0.58431373 0.40784314 0.16862745]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.27058824 0.25098039 0.21568627]\n",
      "   [0.94901961 0.93333333 0.92941176]\n",
      "   [0.90980392 0.90588235 0.88627451]\n",
      "   ...\n",
      "   [0.45882353 0.43137255 0.35686275]\n",
      "   [0.42745098 0.38823529 0.32156863]\n",
      "   [0.41176471 0.39607843 0.33333333]]\n",
      "\n",
      "  [[0.36470588 0.34117647 0.29803922]\n",
      "   [0.38039216 0.37254902 0.35294118]\n",
      "   [0.39215686 0.37254902 0.36078431]\n",
      "   ...\n",
      "   [0.46666667 0.43921569 0.36470588]\n",
      "   [0.45098039 0.41960784 0.35294118]\n",
      "   [0.47843137 0.45098039 0.38431373]]\n",
      "\n",
      "  [[0.43137255 0.40392157 0.35294118]\n",
      "   [0.36862745 0.39215686 0.3372549 ]\n",
      "   [0.45098039 0.41568627 0.36470588]\n",
      "   ...\n",
      "   [0.45098039 0.42352941 0.34901961]\n",
      "   [0.48235294 0.47058824 0.38823529]\n",
      "   [0.4745098  0.44705882 0.36862745]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]]\n",
      "\n",
      "\n",
      " [[[0.2        0.18039216 0.17647059]\n",
      "   [0.2        0.18039216 0.17647059]\n",
      "   [0.2        0.18039216 0.17647059]\n",
      "   ...\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]]\n",
      "\n",
      "  [[0.20392157 0.18431373 0.18039216]\n",
      "   [0.2        0.18039216 0.17647059]\n",
      "   [0.2        0.18039216 0.17647059]\n",
      "   ...\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]]\n",
      "\n",
      "  [[0.20392157 0.18431373 0.18039216]\n",
      "   [0.21176471 0.18431373 0.17254902]\n",
      "   [0.20392157 0.18431373 0.18431373]\n",
      "   ...\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.10980392 0.10196078 0.10196078]\n",
      "   [0.10588235 0.09411765 0.10196078]\n",
      "   [0.10588235 0.09803922 0.10196078]\n",
      "   ...\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]]\n",
      "\n",
      "  [[0.10980392 0.10196078 0.10196078]\n",
      "   [0.10196078 0.09411765 0.09411765]\n",
      "   [0.10196078 0.09803922 0.09803922]\n",
      "   ...\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]]\n",
      "\n",
      "  [[0.10980392 0.10196078 0.10196078]\n",
      "   [0.10588235 0.09803922 0.09803922]\n",
      "   [0.10588235 0.09411765 0.09803922]\n",
      "   ...\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]\n",
      "   [0.00784314 0.00392157 0.01176471]]]\n",
      "\n",
      "\n",
      " [[[0.30980392 0.41960784 0.4627451 ]\n",
      "   [0.33333333 0.43529412 0.48235294]\n",
      "   [0.35686275 0.45098039 0.49803922]\n",
      "   ...\n",
      "   [0.43529412 0.45490196 0.45882353]\n",
      "   [0.37647059 0.39215686 0.39607843]\n",
      "   [0.35294118 0.35686275 0.34901961]]\n",
      "\n",
      "  [[0.31764706 0.42745098 0.47058824]\n",
      "   [0.3372549  0.43921569 0.48627451]\n",
      "   [0.36078431 0.45882353 0.50196078]\n",
      "   ...\n",
      "   [0.43921569 0.45882353 0.46666667]\n",
      "   [0.38039216 0.39607843 0.4       ]\n",
      "   [0.35686275 0.36078431 0.35294118]]\n",
      "\n",
      "  [[0.3254902  0.43529412 0.47843137]\n",
      "   [0.34509804 0.44705882 0.49411765]\n",
      "   [0.36862745 0.4627451  0.50980392]\n",
      "   ...\n",
      "   [0.44705882 0.4627451  0.47058824]\n",
      "   [0.38823529 0.40784314 0.40784314]\n",
      "   [0.36078431 0.36470588 0.35686275]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.55294118 0.58039216 0.60784314]\n",
      "   [0.54117647 0.57254902 0.6       ]\n",
      "   [0.5254902  0.55686275 0.58431373]\n",
      "   ...\n",
      "   [0.10196078 0.10196078 0.1254902 ]\n",
      "   [0.05098039 0.05098039 0.0745098 ]\n",
      "   [0.05490196 0.05490196 0.0745098 ]]\n",
      "\n",
      "  [[0.53333333 0.56470588 0.59215686]\n",
      "   [0.49803922 0.52941176 0.55686275]\n",
      "   [0.4627451  0.49411765 0.52156863]\n",
      "   ...\n",
      "   [0.10196078 0.10196078 0.1254902 ]\n",
      "   [0.12156863 0.12156863 0.14509804]\n",
      "   [0.07058824 0.07058824 0.09411765]]\n",
      "\n",
      "  [[0.48627451 0.51764706 0.54509804]\n",
      "   [0.4627451  0.49411765 0.52156863]\n",
      "   [0.42745098 0.4627451  0.48627451]\n",
      "   ...\n",
      "   [0.06666667 0.06666667 0.09019608]\n",
      "   [0.04313725 0.04313725 0.06666667]\n",
      "   [0.06666667 0.06666667 0.09019608]]]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(new_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_target.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 100, 100, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 100, 100, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(12,(3,3),input_shape=data.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#The first CNN layer followed by Relu and MaxPooling layers\n",
    "\n",
    "model.add(Conv2D(12,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#The second convolution layer followed by Relu and MaxPooling layers\n",
    "\n",
    "\n",
    "model.add(Conv2D(12,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "#Flatten layer to stack the output convolutions from second convolution layer\n",
    "model.add(Dense(12,activation='relu'))\n",
    "#Dense layer of 64 neurons\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "#The Final layer with two outputs for two categories\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 98, 98, 12)        336       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 98, 98, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 49, 49, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 47, 47, 12)        1308      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 47, 47, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 23, 23, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 21, 21, 12)        1308      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 21, 21, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 10, 10, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 12)                14412     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 26        \n",
      "=================================================================\n",
      "Total params: 17,390\n",
      "Trainable params: 17,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,new_target,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.7075 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7232 - accuracy: 0.5000 - val_loss: 0.6992 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6842 - accuracy: 0.5000 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6224 - accuracy: 0.6250 - val_loss: 0.6774 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6664 - accuracy: 0.5000 - val_loss: 0.6693 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7269 - accuracy: 0.5000 - val_loss: 0.6653 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7264 - accuracy: 0.3750 - val_loss: 0.6655 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6252 - accuracy: 0.6250 - val_loss: 0.6621 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6388 - accuracy: 0.7500 - val_loss: 0.6548 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6377 - accuracy: 0.6250 - val_loss: 0.6451 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6527 - accuracy: 0.7500 - val_loss: 0.6316 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6277 - accuracy: 0.8750 - val_loss: 0.6057 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5793 - accuracy: 0.8750 - val_loss: 0.5748 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5792 - accuracy: 0.8750 - val_loss: 0.5455 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5102 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5383 - accuracy: 0.8750 - val_loss: 0.4882 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4792 - accuracy: 0.8750 - val_loss: 0.4614 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4669 - accuracy: 0.8750 - val_loss: 0.4361 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5344 - accuracy: 0.7500 - val_loss: 0.4118 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4105 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3353 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2958 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3648 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3337 - accuracy: 0.8750 - val_loss: 0.3051 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3320 - accuracy: 0.8750 - val_loss: 0.2675 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2940 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2386 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2662 - accuracy: 0.8750 - val_loss: 0.1885 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1496 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1502 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1621 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1655 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1166 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0865 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.1080e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.6642e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.0464e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.4955e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.8733e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 9.0606e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3718e-04 - accuracy: 1.0000 - val_loss: 8.3109e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 7.6069e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0725e-04 - accuracy: 1.0000 - val_loss: 7.0481e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.0159e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.4641e-04 - accuracy: 1.0000 - val_loss: 6.5117e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.6231e-04 - accuracy: 1.0000 - val_loss: 6.0623e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0707e-04 - accuracy: 1.0000 - val_loss: 5.8069e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 4.9618e-04 - accuracy: 1.0000 - val_loss: 5.7128e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 7.2290e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0448e-04 - accuracy: 1.0000 - val_loss: 9.1029e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4187e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.5659e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.2199e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.0625e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.8684e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.3497e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.9774e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.0844e-04 - accuracy: 1.0000 - val_loss: 9.2195e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.8289e-04 - accuracy: 1.0000 - val_loss: 8.4335e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3176e-04 - accuracy: 1.0000 - val_loss: 7.7658e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.8168e-04 - accuracy: 1.0000 - val_loss: 7.2457e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.7384e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.4718e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.5262e-04 - accuracy: 1.0000 - val_loss: 7.0736e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.7759e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.7515e-05 - accuracy: 1.0000 - val_loss: 8.4656e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.6395e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.7283e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.2790e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.1505e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3139e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.4494e-04 - accuracy: 1.0000 - val_loss: 7.3105e-04 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4977e-04 - accuracy: 1.0000 - val_loss: 4.9436e-04 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4060e-04 - accuracy: 1.0000 - val_loss: 3.4678e-04 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.5671e-05 - accuracy: 1.0000 - val_loss: 2.5093e-04 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.5981e-04 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.7282e-05 - accuracy: 1.0000 - val_loss: 2.6857e-04 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.4196e-04 - accuracy: 1.0000 - val_loss: 2.7184e-04 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.9805e-04 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5421e-05 - accuracy: 1.0000 - val_loss: 3.2486e-04 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.2564e-04 - accuracy: 1.0000 - val_loss: 3.5351e-04 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.7259e-05 - accuracy: 1.0000 - val_loss: 3.8204e-04 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.4151e-04 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1897e-04 - accuracy: 1.0000 - val_loss: 7.4135e-04 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.3437e-04 - accuracy: 1.0000 - val_loss: 9.8525e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.9238e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.7161e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5724e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1452e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2075e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.0102e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 7.7002e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5288e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.4219e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.0881e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.5230e-05 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0215e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 7.8588e-05 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2698e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6888e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.4636e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.8611e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 2.6894e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 6.0928e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.6890e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.2762e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.5317e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 9.4591e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 4.0703e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7853e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.2093e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.9498e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.1973e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.2317e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 9.8186e-04 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.3584e-05 - accuracy: 1.0000 - val_loss: 8.4633e-04 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.6163e-04 - accuracy: 1.0000 - val_loss: 7.4367e-04 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4853e-04 - accuracy: 1.0000 - val_loss: 6.5891e-04 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.0969e-04 - accuracy: 1.0000 - val_loss: 6.0051e-04 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.5940e-05 - accuracy: 1.0000 - val_loss: 5.5181e-04 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0180e-04 - accuracy: 1.0000 - val_loss: 5.6063e-04 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.0646e-05 - accuracy: 1.0000 - val_loss: 5.7027e-04 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 4.9241e-04 - accuracy: 1.0000 - val_loss: 5.9676e-04 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.8105e-05 - accuracy: 1.0000 - val_loss: 6.2212e-04 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 6.5290e-05 - accuracy: 1.0000 - val_loss: 6.4349e-04 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.8414e-05 - accuracy: 1.0000 - val_loss: 6.6379e-04 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.8639e-05 - accuracy: 1.0000 - val_loss: 6.8296e-04 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.3588e-05 - accuracy: 1.0000 - val_loss: 7.0082e-04 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.9263e-04 - accuracy: 1.0000 - val_loss: 7.2016e-04 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.0890e-04 - accuracy: 1.0000 - val_loss: 7.3629e-04 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.5232e-05 - accuracy: 1.0000 - val_loss: 7.5385e-04 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.8045e-04 - accuracy: 1.0000 - val_loss: 7.6010e-04 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.5104e-04 - accuracy: 1.0000 - val_loss: 7.5801e-04 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.8339e-05 - accuracy: 1.0000 - val_loss: 7.5617e-04 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.3615e-05 - accuracy: 1.0000 - val_loss: 7.5492e-04 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.1639e-04 - accuracy: 1.0000 - val_loss: 7.4825e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 5.6143e-05 - accuracy: 1.0000 - val_loss: 7.3927e-04 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.9149e-05 - accuracy: 1.0000 - val_loss: 7.2945e-04 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.9839e-04 - accuracy: 1.0000 - val_loss: 7.2956e-04 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.6890e-05 - accuracy: 1.0000 - val_loss: 7.2831e-04 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.8011e-05 - accuracy: 1.0000 - val_loss: 7.2790e-04 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.7171e-04 - accuracy: 1.0000 - val_loss: 6.9391e-04 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2625e-05 - accuracy: 1.0000 - val_loss: 6.6510e-04 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 7.5502e-05 - accuracy: 1.0000 - val_loss: 6.3540e-04 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4.9737e-05 - accuracy: 1.0000 - val_loss: 6.1081e-04 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.4062e-05 - accuracy: 1.0000 - val_loss: 5.8819e-04 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.9697e-05 - accuracy: 1.0000 - val_loss: 5.6836e-04 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.0457e-04 - accuracy: 1.0000 - val_loss: 5.5449e-04 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 2.6448e-05 - accuracy: 1.0000 - val_loss: 5.4306e-04 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 4.6071e-05 - accuracy: 1.0000 - val_loss: 5.3431e-04 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 4.1199e-05 - accuracy: 1.0000 - val_loss: 5.2585e-04 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.6237e-05 - accuracy: 1.0000 - val_loss: 5.1996e-04 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.6220e-05 - accuracy: 1.0000 - val_loss: 5.1323e-04 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.5277e-05 - accuracy: 1.0000 - val_loss: 5.0549e-04 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.3420e-04 - accuracy: 1.0000 - val_loss: 4.9102e-04 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.3747e-05 - accuracy: 1.0000 - val_loss: 4.7738e-04 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.5349e-04 - accuracy: 1.0000 - val_loss: 4.7339e-04 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.2315e-04 - accuracy: 1.0000 - val_loss: 4.8108e-04 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.2465e-05 - accuracy: 1.0000 - val_loss: 4.8828e-04 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.8991e-05 - accuracy: 1.0000 - val_loss: 4.9572e-04 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.8368e-05 - accuracy: 1.0000 - val_loss: 5.0198e-04 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.6595e-05 - accuracy: 1.0000 - val_loss: 5.0966e-04 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.5642e-05 - accuracy: 1.0000 - val_loss: 5.1722e-04 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.7779e-05 - accuracy: 1.0000 - val_loss: 5.2180e-04 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.3774e-05 - accuracy: 1.0000 - val_loss: 5.2579e-04 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.4672e-05 - accuracy: 1.0000 - val_loss: 5.3020e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data,train_target,epochs=200,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "N = 200\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.savefig(\"CNN_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
